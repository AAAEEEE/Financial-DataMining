{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Trainings for Stock Data\n",
    "\n",
    "Here are some non-DL model training processes:\n",
    "\n",
    "* random forest\n",
    "* AdaBoost\n",
    "* XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import tqdm\n",
    "import my_pywt as pywt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('DataSet/TrainSet.csv')\n",
    "df_val = pd.read_csv('DataSet/ValSet.csv')\n",
    "indicators = df_train.columns.values[:108].tolist()\n",
    "market_stat = ['midPrice',  'LastPrice', 'Volume', 'LastVolume', 'Turnover', 'LastTurnover',\n",
    "       'OpenInterest', 'UpperLimitPrice', 'LowerLimitPrice', 'am_pm',\n",
    "       'UpdateMinute']\n",
    "features = indicators + market_stat\n",
    "train_data = df_train[features]\n",
    "train_label = df_train['label']\n",
    "train_data=train_data.values\n",
    "train_label=train_label.values\n",
    "val_data = df_val[features]\n",
    "val_label = df_val['label']\n",
    "val_data=val_data.values\n",
    "val_label=val_label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest for Raw Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_raw = AdaBoostRegressor(DecisionTreeRegressor(max_depth=2),n_estimators=20,learning_rate=1)\n",
    "rf_raw.fit(train_data, train_label)\n",
    "val_pred=rf.predict(val_data)\n",
    "((val_label-val_pred)**2).mean()\n",
    "with open('AdaBoostReg_Raw.pkl','wb') as fh:\n",
    "    pickle.dump(rf_raw, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost for Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_raw = RandomForestRegressor(10, max_depth=7, n_jobs=10)\n",
    "ada_raw.fit(train_data, train_label)\n",
    "val_pred=ada.predict(val_data)\n",
    "((val_label-val_pred)**2).mean()\n",
    "with open('Randomforest_Raw.pkl','wb') as fh:\n",
    "    pickle.dump(ada_raw, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost for Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_data, label=train_label)\n",
    "dval = xgb.DMatrix(val_data, label=val_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_gbtree = {\n",
    "    # General Parameters:\n",
    "    'booster':'gbtree',\n",
    "    # For GBtree\n",
    "    'eta':0.1,\n",
    "    'gamma': 0,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 0.9,\n",
    "    'lambda': 0.5,\n",
    "    'alpha': 0,\n",
    "    'tree_method': 'auto', \n",
    "    'num_parallel_tree': 1, # For Random Forest\n",
    "    # Learning Task\n",
    "#     'objective': 'reg:squarederror',\n",
    "    'eval_metric': ['rmse']\n",
    "}\n",
    "evallist = [(dtrain, 'train'),(dval, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 100\n",
    "bst_gbtree_raw = xgb.train(param_gbtree, dtrain, num_round, evallist, early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_gbtree_raw.save_model('XGBoosting_GBtree.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data with WT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_WT = np.empty((2,*train_data.shape))\n",
    "for j in tqdm(range(len(train_data[0]))):\n",
    "    A, D = pywt.wavelet_transform(train_data[:,j])\n",
    "    train_data_WT[0,:,j] = A[:]\n",
    "    train_data_WT[1,:,j] = D[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_WT = np.empty((2,*val_data.shape))\n",
    "for j in tqdm(range(len(val_data[0]))):\n",
    "    A, D = pywt.wavelet_transform(val_data[:,j])\n",
    "    val_data_WT[0,:,j] = A[:]\n",
    "    val_data_WT[1,:,j] = D[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_WT_merge = np.concatenate((train_data_WT[0],train_data_WT[1]),1)\n",
    "val_data_WT_merge = np.concatenate((val_data_WT[0],val_data_WT[1]),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest for Data with WT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_WT = RandomForestRegressor(10, max_depth=7, n_jobs=10)\n",
    "rf_WT.fit(train_data_WT_merge, train_label)\n",
    "val_pred1=rf1.predict(val_data_WT_merge)\n",
    "((val_label-val_pred1)**2).mean()\n",
    "with open('Randomforest_WT.pkl','wb') as fh1:\n",
    "    pickle.dump(rf_WT, fh1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost for Data with WT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_WT = AdaBoostRegressor(DecisionTreeRegressor(max_depth=2),n_estimators=20,learning_rate=1)\n",
    "ada_WT.fit(train_data_WT_merge, train_label)\n",
    "val_pred1=ada_WT.predict(val_data_WT_merge)\n",
    "((val_label-val_pred1)**2).mean()\n",
    "with open('AdaBoostReg_WT.pkl','wb') as fh:\n",
    "    pickle.dump(ada_WT, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost for Data with WT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_data_WT_merge, label=train_label)\n",
    "dval = xgb.DMatrix(val_data_WT_merge, label=val_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_gbtree = {\n",
    "    # General Parameters:\n",
    "    'booster':'gbtree',\n",
    "    # For GBtree\n",
    "    'eta':0.1,\n",
    "    'gamma': 0,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 0.9,\n",
    "    'lambda': 0.5,\n",
    "    'alpha': 0,\n",
    "    'tree_method': 'auto', \n",
    "    'num_parallel_tree': 1, # For Random Forest\n",
    "    # Learning Task\n",
    "#     'objective': 'reg:squarederror',\n",
    "    'eval_metric': ['rmse']\n",
    "}\n",
    "evallist = [(dtrain, 'train'),(dval, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 100\n",
    "bst_gbtree_WT = xgb.train(param_gbtree, dtrain, num_round, evallist, early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_gbtree_WT.save_model('XGBoosting_GBtree_WT.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data with DFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dfs = pd.read_csv('DataSet/Dataset_DFSn.csv')\n",
    "df_train_dfs = df_train_dfs.values\n",
    "indicators = df_train.columns.values[:108].tolist()\n",
    "market_stat = ['midPrice',  'LastPrice', 'Volume', 'LastVolume', 'Turnover', 'LastTurnover',\n",
    "       'OpenInterest', 'UpperLimitPrice', 'LowerLimitPrice',] # 'am_pm',\n",
    "#        'UpdateMinute']\n",
    "features = indicators + market_stat\n",
    "play_data = ['indicator4','indicator88','indicator2','indicator83','indicator75','midPrice',  'LastPrice', 'Volume', 'LastVolume', 'Turnover', 'LastTurnover',\n",
    "       'OpenInterest', 'UpperLimitPrice', 'LowerLimitPrice']\n",
    "for i in range(len(play_data)):\n",
    "    features = features + [play_data[i]+'_mean',play_data[i]+'_std',play_data[i]+'_diff']\n",
    "df_train_dfs = df_train_dfs[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_dfs = pd.read_csv('DataSet/Dataset_DFSn_val.csv')\n",
    "df_val_dfs = df_val_dfs[features].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest for Data with DFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_dfs = RandomForestRegressor(10, max_depth=7, n_jobs=10)\n",
    "rf_dfs.fit(df_train_dfs, train_label)\n",
    "val_pred2=rf_dfs.predict(df_val_dfs)\n",
    "((val_label-val_pred2)**2).mean()\n",
    "with open('Randomforest_DFS.pkl','wb') as fh:\n",
    "    pickle.dump(rf_dfs, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost for Data with DFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_DFS = AdaBoostRegressor(DecisionTreeRegressor(max_depth=2),n_estimators=20,learning_rate=1)\n",
    "ada_DFS.fit(df_train_dfs, train_label)\n",
    "val_pred2=ada_DFS.predict(df_val_dfs)\n",
    "((val_label-val_pred2)**2).mean()\n",
    "with open('AdaBoostReg_DFS.pkl','wb') as fh:\n",
    "    pickle.dump(ada_DFS, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost for Data with DFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(df_train_dfs, label=train_label)\n",
    "dval = xgb.DMatrix(df_val_dfs, label=val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_gbtree = {\n",
    "    # General Parameters:\n",
    "    'booster':'gbtree',\n",
    "    # For GBtree\n",
    "    'eta':0.1,\n",
    "    'gamma': 0,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 0.9,\n",
    "    'lambda': 0.5,\n",
    "    'alpha': 0,\n",
    "    'tree_method': 'auto', \n",
    "    'num_parallel_tree': 1, # For Random Forest\n",
    "    # Learning Task\n",
    "#     'objective': 'reg:squarederror',\n",
    "    'eval_metric': ['rmse']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evallist = [(dtrain, 'train'),(dval, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 200\n",
    "bst_gbtree_DFS = xgb.train(param_gbtree, dtrain, num_round, evallist, early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_gbtree_DFS.save_model('XGBoosting_GBtree_WT.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
